{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Extracting features from scraped data](#extracting-features-from-scraped-data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext lab_black\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from pathlib import Path\n",
    "from time import strftime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", 1000)\n",
    "pd.set_option(\"display.max_columns\", 500)\n",
    "pd.set_option(\"display.width\", 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"toc\"></a>\n",
    "\n",
    "## [Table of Contents](#table-of-contents)\n",
    "0. [About](#load-data)\n",
    "1. [User Inputs](#user-inputs)\n",
    "2. [Load data](#load-data)\n",
    "3. [Feature Engineering](#feature-engineering)\n",
    "4. [Export to processed data file](#export-to-processed-data-file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"about\"></a>\n",
    "\n",
    "## 0. [About](#about)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will extract new features from the data stored in the `*.csv` files in `data/*.csv`. The total number of listings retrieved for each city is shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"AUS\", f\"Number of pages of listings: {len(glob('data/AUS/*.csv'))}\")\n",
    "print(\"SEA\", f\"Number of pages of listings: {len(glob('data/SEA/*.csv'))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"user-inputs\"></a>\n",
    "\n",
    "## 1. [User Inputs](#user-inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each city, we'll specify how many `*.csv` files of scraped car listings data to work with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "n_files_per_city = {\n",
    "    \"AUS\": 29,\n",
    "    \"SEA\": 22,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_id = \"_\".join([f\"{k}{v}\" for k, v in n_files_per_city.items()]) + \"_2SEAzipcodes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_files = sum(n_files_per_city.values())\n",
    "number_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also specify here the features that we will want to work with in our regression analysis. Missing data will be dropped based on these columns. In this way, missing values in other columns will not affect the subset of features we want to focus on here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_nums = [\"MPG\", \"tank_volume\"]  # \"Highway MPG\" + \"City MPG\",\n",
    "eng_cats = [\n",
    "    \"year\",\n",
    "    \"make\",\n",
    "    \"model\",\n",
    "    \"trans_speed\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nums = [\n",
    "    \"Mileage\",\n",
    "    \"consumer_reviews\",\n",
    "    \"seller_reviews\",\n",
    "    \"price\",\n",
    "]\n",
    "cats = [\n",
    "    \"Fuel Type\",\n",
    "    \"Drivetrain\",\n",
    "    \"seller_rating\",\n",
    "    \"consumer_stars\",\n",
    "    \"Comfort\",\n",
    "    \"Performance\",\n",
    "    \"Reliability\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"load-data\"></a>\n",
    "\n",
    "## 2. [Load data](#load-data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll begin by loading all `*.csv` files in `data/*.csv` into a single Pandas `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir_path = Path().cwd() / \"data\"\n",
    "print(data_dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(glob(str(data_dir_path / \"*\" / \"*.csv\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(\n",
    "    [pd.read_csv(f, sep=\",\") for f in glob(str(data_dir_path / \"*\" / \"*.csv\"))],\n",
    "    ignore_index=True,\n",
    ")\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"feature-engineering\"></a>\n",
    "\n",
    "## 3. [Feature Engineering](#feature-engineering)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start by finding the number of missing values in the features and target (`price`) columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[nums + cats + [\"price\"]].isna().sum().to_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see there are missing values, but we won't drop these here. We'll put that step into a pre-processing pipeline that can be modified immediately before analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll drop observations where the listing title is stored as the string `title` - this is a duplicate of the the header row and is a consequence of how the file was loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[(~df[\"title\"].str.contains(\"title\"))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll append new features to the loaded data, by extracting parts of existing features. The existing features will be retained in the data. Here, we will extract the tank volume from the engine information that was scraped. We'l do this with a [regular expression](https://en.wikipedia.org/wiki/Regular_expression) that extracts the numeric part of the `Engine` column, which will give the volume. We'll then convert this extracted string from a string into a `float`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"tank_volume\"] = (\n",
    "    df[\"Engine\"]\n",
    "    .str.split(\"L\", expand=True)[0]\n",
    "    .str.strip()\n",
    "    .str.extract(\"(\\d\\.\\d)\", expand=False)\n",
    "    .astype(float)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll get the `make` and `model` from the `title`, since these are not explicitly provided in the listing and it seems intuitive that these categorical features would be helpful in predicting price of the car. Again, we'll use regular expression to help extract this information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"year\"] = df[\"title\"].str.extract(\"(\\d+)\").astype(int)\n",
    "df[\"make_model\"] = df[\"title\"].str.replace(\"\\d+ \", \"\")\n",
    "df[[\"make\", \"model\"]] = df[\"make_model\"].str.split(\" \", 1, expand=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll get the `City` and `State` from the `seller_address` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"City\", \"State\"]] = df[\"seller_address\"].str.extract(\n",
    "    r\"((?P<City>[A-Z][a-z]+),\\s(?P<State>[A-Z]{2}))\", expand=False\n",
    ")[[\"City\", \"State\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the transmission determines the proper quantity of power delivered to the wheels to allow the car to be driven at a specific speed, we'll extract the transmission speed from the `Transmission` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"trans_speed\"] = df[\"Transmission\"].str.split(\"-Speed\", expand=True)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll calculate the interest, in dollars, to be paid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"interest\"] = (df[\"per_month_min\"].astype(float) * 60) - df[\"price\"].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we'll convert the `Mileage` column from a string into a numeric one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Mileage\"] = df.loc[df[\"Mileage\"] != \"Not provided\"][\"Mileage\"].str.replace(\",\", \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll also combine `Highway MPG` and `City MPG` into a single feature named `MPG`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"MPG\"] = df[\"Highway MPG\"] + df[\"City MPG\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[nums + cats + eng_nums + eng_cats + [\"price\"]].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[nums + cats + eng_nums + eng_cats + [\"price\"]].dropna(how='any').isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we'll convert the `price` column from a string into a `float`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"price\"] = df[\"price\"].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2 = df[nums + cats + eng_nums + eng_cats + [\"price\"]].copy()\n",
    "# df2.dropna(how='any', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2[nums + cats + eng_nums + eng_cats + [\"price\"]].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2[nums + cats + eng_cats + eng_nums].dropna(how=\"any\").shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2[nums + cats + eng_cats + eng_nums].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2[nums + cats].dropna(how=\"any\").shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_cols = [\n",
    "#     \"Engine\",\n",
    "#     \"tank_volume\",\n",
    "#     \"year\",\n",
    "#     \"make\",\n",
    "#     \"model\",\n",
    "#     \"seller_address\",\n",
    "#     \"City\",\n",
    "#     \"State\",\n",
    "#     \"MPG\",\n",
    "#     \"Mileage\",\n",
    "#     \"trans_speed\",\n",
    "#     \"interest\"\n",
    "# ]\n",
    "# df[new_cols].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"export-to-processed-data-file\"></a>\n",
    "\n",
    "## 4. [Export to processed data file](#export-to-processed-data-file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we'll export the processed data to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\n",
    "    str(data_dir_path / f\"processed_data__{file_id}_{strftime('%Y%m%d_%H%M%S')}.csv\"),\n",
    "    index=False,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
